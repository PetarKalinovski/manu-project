{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:48:49.927859Z",
     "start_time": "2025-01-06T12:48:49.906863Z"
    }
   },
   "cell_type": "code",
   "source": "import torch",
   "id": "95c2a881779b79e2",
   "outputs": [],
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-06T12:48:49.943118Z",
     "start_time": "2025-01-06T12:48:49.934238Z"
    }
   },
   "source": [
    "import torch\n",
    "from sympy.printing.tensorflow import tensorflow"
   ],
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:48:52.271407Z",
     "start_time": "2025-01-06T12:48:49.958316Z"
    }
   },
   "cell_type": "code",
   "source": "pip install torch-geometric",
   "id": "7d1fe6925ac49011",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch-geometric in c:\\users\\dell\\pycharmprojects\\manu_factoid_gcn\\.venv\\lib\\site-packages (2.6.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\dell\\pycharmprojects\\manu_factoid_gcn\\.venv\\lib\\site-packages (from torch-geometric) (3.10.10)\n",
      "Requirement already satisfied: fsspec in c:\\users\\dell\\pycharmprojects\\manu_factoid_gcn\\.venv\\lib\\site-packages (from torch-geometric) (2024.10.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dell\\pycharmprojects\\manu_factoid_gcn\\.venv\\lib\\site-packages (from torch-geometric) (3.1.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\dell\\pycharmprojects\\manu_factoid_gcn\\.venv\\lib\\site-packages (from torch-geometric) (1.26.4)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\dell\\pycharmprojects\\manu_factoid_gcn\\.venv\\lib\\site-packages (from torch-geometric) (6.1.0)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\dell\\pycharmprojects\\manu_factoid_gcn\\.venv\\lib\\site-packages (from torch-geometric) (3.2.0)\n",
      "Requirement already satisfied: requests in c:\\users\\dell\\pycharmprojects\\manu_factoid_gcn\\.venv\\lib\\site-packages (from torch-geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dell\\pycharmprojects\\manu_factoid_gcn\\.venv\\lib\\site-packages (from torch-geometric) (4.67.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\dell\\pycharmprojects\\manu_factoid_gcn\\.venv\\lib\\site-packages (from aiohttp->torch-geometric) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\dell\\pycharmprojects\\manu_factoid_gcn\\.venv\\lib\\site-packages (from aiohttp->torch-geometric) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dell\\pycharmprojects\\manu_factoid_gcn\\.venv\\lib\\site-packages (from aiohttp->torch-geometric) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dell\\pycharmprojects\\manu_factoid_gcn\\.venv\\lib\\site-packages (from aiohttp->torch-geometric) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dell\\pycharmprojects\\manu_factoid_gcn\\.venv\\lib\\site-packages (from aiohttp->torch-geometric) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\dell\\pycharmprojects\\manu_factoid_gcn\\.venv\\lib\\site-packages (from aiohttp->torch-geometric) (1.17.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\dell\\pycharmprojects\\manu_factoid_gcn\\.venv\\lib\\site-packages (from aiohttp->torch-geometric) (4.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dell\\pycharmprojects\\manu_factoid_gcn\\.venv\\lib\\site-packages (from jinja2->torch-geometric) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\pycharmprojects\\manu_factoid_gcn\\.venv\\lib\\site-packages (from requests->torch-geometric) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\pycharmprojects\\manu_factoid_gcn\\.venv\\lib\\site-packages (from requests->torch-geometric) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\pycharmprojects\\manu_factoid_gcn\\.venv\\lib\\site-packages (from requests->torch-geometric) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\pycharmprojects\\manu_factoid_gcn\\.venv\\lib\\site-packages (from requests->torch-geometric) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\pycharmprojects\\manu_factoid_gcn\\.venv\\lib\\site-packages (from tqdm->torch-geometric) (0.4.6)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\dell\\pycharmprojects\\manu_factoid_gcn\\.venv\\lib\\site-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\dell\\pycharmprojects\\manu_factoid_gcn\\.venv\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp->torch-geometric) (0.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:48:52.335212Z",
     "start_time": "2025-01-06T12:48:52.319468Z"
    }
   },
   "cell_type": "code",
   "source": "from torch_geometric.data import Data",
   "id": "98f20b94751b75cd",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:48:52.367055Z",
     "start_time": "2025-01-06T12:48:52.344045Z"
    }
   },
   "cell_type": "code",
   "source": "data=torch.load('graph_data_with_txt.pt')",
   "id": "1f9229f1db84387a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_15844\\951303083.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data=torch.load('graph_data_with_txt.pt')\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:48:52.399164Z",
     "start_time": "2025-01-06T12:48:52.385227Z"
    }
   },
   "cell_type": "code",
   "source": "#data.y[data.y == -1] = 3",
   "id": "5f07bf554ee0d2a0",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:48:52.431093Z",
     "start_time": "2025-01-06T12:48:52.415047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# num_nodes = data.num_nodes\n",
    "# num_train = int(0.8 * num_nodes)\n",
    "# train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "# train_mask[:num_train] = 1"
   ],
   "id": "d6273ef2ccdbf3dd",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:48:52.462470Z",
     "start_time": "2025-01-06T12:48:52.446799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# data.train_mask = train_mask\n",
    "# data.test_mask = ~train_mask"
   ],
   "id": "dad495538008a783",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:48:52.494293Z",
     "start_time": "2025-01-06T12:48:52.478209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_nodes = data.num_nodes\n",
    "train_ratio, val_ratio = 0.8, 0.1  # 80% train, 10% val, 10% test\n",
    "\n",
    "perm = torch.randperm(num_nodes)\n",
    "train_size = int(train_ratio * num_nodes)\n",
    "val_size = int(val_ratio * num_nodes)\n",
    "\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "train_mask[perm[:train_size]] = True\n",
    "val_mask[perm[train_size:train_size + val_size]] = True\n",
    "test_mask[perm[train_size + val_size:]] = True\n",
    "\n",
    "data.train_mask = train_mask\n",
    "data.val_mask = val_mask\n",
    "data.test_mask = test_mask"
   ],
   "id": "312d7d09fee2387a",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:48:52.525344Z",
     "start_time": "2025-01-06T12:48:52.510081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn.functional import dropout\n",
    "from torch_geometric.nn import GCNConv, Linear, SAGEConv"
   ],
   "id": "295b18c0e78a9ac5",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:48:52.556960Z",
     "start_time": "2025-01-06T12:48:52.541184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch.nn import Linear, Dropout, LeakyReLU\n"
   ],
   "id": "d691ce6eda3a6144",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:48:52.594850Z",
     "start_time": "2025-01-06T12:48:52.575448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.nn import Linear, Dropout, Sigmoid\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import SAGEConv\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(-1, 64)\n",
    "        self.conv2 = GCNConv(64, 128)\n",
    "        self.conv3 = GCNConv(128, 256)\n",
    "        self.conv4 = GCNConv(256, 512)\n",
    "        self.linear = Linear(512, 256)\n",
    "        self.linear1=Linear(256,128)\n",
    "        self.linear2 = Linear(128, 64)\n",
    "        self.linear3 = Linear(64, 1)\n",
    "        self.dropout = Dropout(p=0.4)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        x = self.conv1(x, edge_index, edge_weight=edge_weight)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.conv2(x, edge_index, edge_weight=edge_weight)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.conv3(x,edge_index, edge_weight=edge_weight)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.conv4(x,edge_index, edge_weight=edge_weight)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # x = self.conv5(x,edge_index)\n",
    "        # x = torch.relu(x)\n",
    "        # x = self.dropout(x)\n",
    "        x=self.linear(x)\n",
    "        x=self.linear1(x)\n",
    "        x=self.linear2(x)\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ],
   "id": "1a64deea56f33079",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:48:52.625689Z",
     "start_time": "2025-01-06T12:48:52.609994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.nn import Linear, Dropout, Sigmoid\n",
    "from torch_geometric.nn import SAGEConv\n",
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(-1, 64)\n",
    "        self.conv2 = SAGEConv(64, 128)\n",
    "        self.conv3 = SAGEConv(128, 256)\n",
    "        self.conv4 = SAGEConv(256, 512)\n",
    "        self.linear = Linear(512, 256)\n",
    "        self.linear1=Linear(256,128)\n",
    "        self.linear2 = Linear(128, 64)\n",
    "        self.linear3 = Linear(64, 1)\n",
    "        self.dropout = Dropout(p=0.4)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.conv3(x,edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.conv4(x,edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # x = self.conv5(x,edge_index)\n",
    "        # x = torch.relu(x)\n",
    "        # x = self.dropout(x)\n",
    "        x=self.linear(x)\n",
    "        x=self.linear1(x)\n",
    "        x=self.linear2(x)\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ],
   "id": "585813aab42a1ca5",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:48:52.657427Z",
     "start_time": "2025-01-06T12:48:52.643029Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# def train(model, dataset, optimizer, criterion, epochs=5):\n",
    "#     train_mask = dataset.train_mask\n",
    "#     for epoch in range(epochs):\n",
    "#         model.train()\n",
    "#         optimizer.zero_grad()\n",
    "#         out = model(dataset.x, dataset.edge_index,dataset.edge_weight).squeeze()  # Output shape: [num_nodes]\n",
    "#         loss = criterion(out[train_mask], dataset.y[train_mask].float()) \n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')"
   ],
   "id": "84eb9b984caffb00",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:48:52.689283Z",
     "start_time": "2025-01-06T12:48:52.674052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(model, dataset, optimizer, criterion, epochs=5):\n",
    "    train_mask = dataset.train_mask\n",
    "    val_mask = dataset.val_mask  # Assuming `val_mask` is available in the dataset\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        out = model(dataset.x, dataset.edge_index, dataset.edge_weight).squeeze()\n",
    "        \n",
    "        # Compute loss on the training set\n",
    "        loss = criterion(out[train_mask], dataset.y[train_mask].float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Validation Performance\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_out = out[val_mask]\n",
    "            val_loss = criterion(val_out, dataset.y[val_mask].float())\n",
    "            val_pred = (torch.sigmoid(val_out) > 0.5).long()\n",
    "            # val_acc = accuracy_score(dataset.y[val_mask].cpu(), val_pred.cpu())\n",
    "        \n",
    "        print(f'Epoch: {epoch:03d}, Train Loss: {loss:.4f}, Val Loss: {val_loss:.4f}')"
   ],
   "id": "baa398050c3b9165",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:48:52.720696Z",
     "start_time": "2025-01-06T12:48:52.706061Z"
    }
   },
   "cell_type": "code",
   "source": "data",
   "id": "643bd6d6435875d1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[4150, 66], edge_index=[2, 439838], y=[4150], edge_weights=[0], train_mask=[4150], val_mask=[4150], test_mask=[4150])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:57:47.744188Z",
     "start_time": "2025-01-06T12:57:47.724080Z"
    }
   },
   "cell_type": "code",
   "source": "model_gcn = GCN()",
   "id": "7872b7da23a988d9",
   "outputs": [],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:57:48.946415Z",
     "start_time": "2025-01-06T12:57:48.861716Z"
    }
   },
   "cell_type": "code",
   "source": "model_sage=SAGE()",
   "id": "1079aa9478fc5ee9",
   "outputs": [],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:57:49.409149Z",
     "start_time": "2025-01-06T12:57:49.393315Z"
    }
   },
   "cell_type": "code",
   "source": "model_gcn",
   "id": "70265206dc300beb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (conv1): GCNConv(-1, 64)\n",
       "  (conv2): GCNConv(64, 128)\n",
       "  (conv3): GCNConv(128, 256)\n",
       "  (conv4): GCNConv(256, 512)\n",
       "  (linear): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (linear1): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (linear3): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.4, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 102
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T13:02:29.751666Z",
     "start_time": "2025-01-06T13:02:29.737046Z"
    }
   },
   "cell_type": "code",
   "source": "optimizer = Adam(model_gcn.parameters(), lr=0.001)",
   "id": "a2ddefde61ff0a02",
   "outputs": [],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:57:51.903201Z",
     "start_time": "2025-01-06T12:57:51.886956Z"
    }
   },
   "cell_type": "code",
   "source": "criterion = torch.nn.BCEWithLogitsLoss()",
   "id": "304689634bcd4ba3",
   "outputs": [],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:48:52.913083Z",
     "start_time": "2025-01-06T12:48:52.897012Z"
    }
   },
   "cell_type": "code",
   "source": "(data.y == 0).sum().item()",
   "id": "8c00927cc006f628",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3064"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T13:00:41.203476Z",
     "start_time": "2025-01-06T13:00:41.105560Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train(model=model_sage, dataset=data,\n",
    "      criterion=criterion, optimizer=optimizer,\n",
    "      epochs=50)"
   ],
   "id": "4cfaf0539a513844",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SAGE.forward() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[107], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_sage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m      \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m      \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[79], line 9\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, dataset, optimizer, criterion, epochs)\u001B[0m\n\u001B[0;32m      6\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# Forward pass\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge_weight\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39msqueeze()\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# Compute loss on the training set\u001B[39;00m\n\u001B[0;32m     12\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(out[train_mask], dataset\u001B[38;5;241m.\u001B[39my[train_mask]\u001B[38;5;241m.\u001B[39mfloat())\n",
      "File \u001B[1;32m~\\PycharmProjects\\Manu_factoid_GCN\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\PycharmProjects\\Manu_factoid_GCN\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[1;31mTypeError\u001B[0m: SAGE.forward() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "execution_count": 107
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T13:05:08.371961Z",
     "start_time": "2025-01-06T13:02:47.121759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train(model=model_gcn, dataset=data,\n",
    "      criterion=criterion, optimizer=optimizer,\n",
    "      epochs=50)"
   ],
   "id": "bfc051a13aa5f54b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Train Loss: 0.5096, Val Loss: 0.5306\n",
      "Epoch: 001, Train Loss: 0.5005, Val Loss: 0.5409\n",
      "Epoch: 002, Train Loss: 0.5029, Val Loss: 0.5461\n",
      "Epoch: 003, Train Loss: 0.5027, Val Loss: 0.5456\n",
      "Epoch: 004, Train Loss: 0.4986, Val Loss: 0.5382\n",
      "Epoch: 005, Train Loss: 0.5016, Val Loss: 0.5487\n",
      "Epoch: 006, Train Loss: 0.5014, Val Loss: 0.5259\n",
      "Epoch: 007, Train Loss: 0.5011, Val Loss: 0.5292\n",
      "Epoch: 008, Train Loss: 0.5020, Val Loss: 0.5319\n",
      "Epoch: 009, Train Loss: 0.4971, Val Loss: 0.5361\n",
      "Epoch: 010, Train Loss: 0.4966, Val Loss: 0.5256\n",
      "Epoch: 011, Train Loss: 0.4998, Val Loss: 0.5378\n",
      "Epoch: 012, Train Loss: 0.4930, Val Loss: 0.5313\n",
      "Epoch: 013, Train Loss: 0.4925, Val Loss: 0.5357\n",
      "Epoch: 014, Train Loss: 0.4978, Val Loss: 0.5473\n",
      "Epoch: 015, Train Loss: 0.4919, Val Loss: 0.5384\n",
      "Epoch: 016, Train Loss: 0.4971, Val Loss: 0.5315\n",
      "Epoch: 017, Train Loss: 0.4920, Val Loss: 0.5293\n",
      "Epoch: 018, Train Loss: 0.4948, Val Loss: 0.5310\n",
      "Epoch: 019, Train Loss: 0.4949, Val Loss: 0.5348\n",
      "Epoch: 020, Train Loss: 0.4960, Val Loss: 0.5308\n",
      "Epoch: 021, Train Loss: 0.4944, Val Loss: 0.5326\n",
      "Epoch: 022, Train Loss: 0.4905, Val Loss: 0.5298\n",
      "Epoch: 023, Train Loss: 0.4952, Val Loss: 0.5377\n",
      "Epoch: 024, Train Loss: 0.4923, Val Loss: 0.5228\n",
      "Epoch: 025, Train Loss: 0.4968, Val Loss: 0.5444\n",
      "Epoch: 026, Train Loss: 0.4932, Val Loss: 0.5265\n",
      "Epoch: 027, Train Loss: 0.4915, Val Loss: 0.5202\n",
      "Epoch: 028, Train Loss: 0.4924, Val Loss: 0.5242\n",
      "Epoch: 029, Train Loss: 0.4962, Val Loss: 0.5195\n",
      "Epoch: 030, Train Loss: 0.4942, Val Loss: 0.5351\n",
      "Epoch: 031, Train Loss: 0.5015, Val Loss: 0.5421\n",
      "Epoch: 032, Train Loss: 0.4942, Val Loss: 0.5383\n",
      "Epoch: 033, Train Loss: 0.4949, Val Loss: 0.5331\n",
      "Epoch: 034, Train Loss: 0.4933, Val Loss: 0.5387\n",
      "Epoch: 035, Train Loss: 0.4929, Val Loss: 0.5250\n",
      "Epoch: 036, Train Loss: 0.4951, Val Loss: 0.5261\n",
      "Epoch: 037, Train Loss: 0.4957, Val Loss: 0.5289\n",
      "Epoch: 038, Train Loss: 0.4922, Val Loss: 0.5286\n",
      "Epoch: 039, Train Loss: 0.5023, Val Loss: 0.5209\n",
      "Epoch: 040, Train Loss: 0.4927, Val Loss: 0.5419\n",
      "Epoch: 041, Train Loss: 0.4909, Val Loss: 0.5338\n",
      "Epoch: 042, Train Loss: 0.4918, Val Loss: 0.5322\n",
      "Epoch: 043, Train Loss: 0.4947, Val Loss: 0.5290\n",
      "Epoch: 044, Train Loss: 0.4953, Val Loss: 0.5526\n",
      "Epoch: 045, Train Loss: 0.4895, Val Loss: 0.5431\n",
      "Epoch: 046, Train Loss: 0.4959, Val Loss: 0.5457\n",
      "Epoch: 047, Train Loss: 0.4935, Val Loss: 0.5364\n",
      "Epoch: 048, Train Loss: 0.4943, Val Loss: 0.5276\n",
      "Epoch: 049, Train Loss: 0.4941, Val Loss: 0.5262\n",
      "Epoch: 050, Train Loss: 0.4889, Val Loss: 0.5286\n",
      "Epoch: 051, Train Loss: 0.4929, Val Loss: 0.5251\n",
      "Epoch: 052, Train Loss: 0.4925, Val Loss: 0.5285\n",
      "Epoch: 053, Train Loss: 0.4936, Val Loss: 0.5380\n",
      "Epoch: 054, Train Loss: 0.4892, Val Loss: 0.5396\n",
      "Epoch: 055, Train Loss: 0.4891, Val Loss: 0.5388\n",
      "Epoch: 056, Train Loss: 0.4895, Val Loss: 0.5287\n",
      "Epoch: 057, Train Loss: 0.4945, Val Loss: 0.5463\n",
      "Epoch: 058, Train Loss: 0.4950, Val Loss: 0.5274\n",
      "Epoch: 059, Train Loss: 0.4922, Val Loss: 0.5416\n",
      "Epoch: 060, Train Loss: 0.4902, Val Loss: 0.5375\n",
      "Epoch: 061, Train Loss: 0.4987, Val Loss: 0.5224\n",
      "Epoch: 062, Train Loss: 0.4950, Val Loss: 0.5238\n",
      "Epoch: 063, Train Loss: 0.4911, Val Loss: 0.5332\n",
      "Epoch: 064, Train Loss: 0.4945, Val Loss: 0.5184\n",
      "Epoch: 065, Train Loss: 0.4912, Val Loss: 0.5288\n",
      "Epoch: 066, Train Loss: 0.4917, Val Loss: 0.5376\n",
      "Epoch: 067, Train Loss: 0.4944, Val Loss: 0.5232\n",
      "Epoch: 068, Train Loss: 0.4893, Val Loss: 0.5254\n",
      "Epoch: 069, Train Loss: 0.4947, Val Loss: 0.5458\n",
      "Epoch: 070, Train Loss: 0.4877, Val Loss: 0.5310\n",
      "Epoch: 071, Train Loss: 0.4916, Val Loss: 0.5243\n",
      "Epoch: 072, Train Loss: 0.4980, Val Loss: 0.5390\n",
      "Epoch: 073, Train Loss: 0.4951, Val Loss: 0.5345\n",
      "Epoch: 074, Train Loss: 0.4898, Val Loss: 0.5282\n",
      "Epoch: 075, Train Loss: 0.4977, Val Loss: 0.5305\n",
      "Epoch: 076, Train Loss: 0.4974, Val Loss: 0.5288\n",
      "Epoch: 077, Train Loss: 0.4902, Val Loss: 0.5386\n",
      "Epoch: 078, Train Loss: 0.4908, Val Loss: 0.5373\n",
      "Epoch: 079, Train Loss: 0.4947, Val Loss: 0.5442\n",
      "Epoch: 080, Train Loss: 0.4950, Val Loss: 0.5447\n",
      "Epoch: 081, Train Loss: 0.4913, Val Loss: 0.5266\n",
      "Epoch: 082, Train Loss: 0.4906, Val Loss: 0.5365\n",
      "Epoch: 083, Train Loss: 0.4918, Val Loss: 0.5256\n",
      "Epoch: 084, Train Loss: 0.4907, Val Loss: 0.5261\n",
      "Epoch: 085, Train Loss: 0.4920, Val Loss: 0.5360\n",
      "Epoch: 086, Train Loss: 0.4923, Val Loss: 0.5295\n",
      "Epoch: 087, Train Loss: 0.4926, Val Loss: 0.5364\n",
      "Epoch: 088, Train Loss: 0.4959, Val Loss: 0.5505\n",
      "Epoch: 089, Train Loss: 0.4938, Val Loss: 0.5346\n",
      "Epoch: 090, Train Loss: 0.4903, Val Loss: 0.5487\n",
      "Epoch: 091, Train Loss: 0.4949, Val Loss: 0.5160\n",
      "Epoch: 092, Train Loss: 0.4943, Val Loss: 0.5257\n",
      "Epoch: 093, Train Loss: 0.4888, Val Loss: 0.5319\n",
      "Epoch: 094, Train Loss: 0.4955, Val Loss: 0.5357\n",
      "Epoch: 095, Train Loss: 0.4886, Val Loss: 0.5369\n",
      "Epoch: 096, Train Loss: 0.4907, Val Loss: 0.5254\n",
      "Epoch: 097, Train Loss: 0.4907, Val Loss: 0.5234\n",
      "Epoch: 098, Train Loss: 0.4873, Val Loss: 0.5166\n",
      "Epoch: 099, Train Loss: 0.4898, Val Loss: 0.5426\n"
     ]
    }
   ],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:51:19.322475Z",
     "start_time": "2025-01-06T12:51:19.307935Z"
    }
   },
   "cell_type": "code",
   "source": "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score",
   "id": "5cf7731c0db13495",
   "outputs": [],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T13:05:30.445062Z",
     "start_time": "2025-01-06T13:05:30.425877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test(model, dataset):\n",
    "    model.eval()\n",
    "    test_mask = dataset.test_mask\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model(dataset.x, dataset.edge_index, dataset.edge_weight).squeeze()\n",
    "        test_out = out[test_mask]\n",
    "        test_pred = (torch.sigmoid(test_out) > 0.5).long()\n",
    "        test_labels = dataset.y[test_mask]\n",
    "\n",
    "    # Calculate metrics\n",
    "    test_acc = accuracy_score(test_labels.cpu(), test_pred.cpu())\n",
    "    test_precision = precision_score(test_labels.cpu(), test_pred.cpu(), average='macro')\n",
    "    test_recall = recall_score(test_labels.cpu(), test_pred.cpu(), average='macro')\n",
    "    test_f1 = f1_score(test_labels.cpu(), test_pred.cpu(), average='macro')\n",
    "\n",
    "    print(f'Test Accuracy: {test_acc:}')\n",
    "    print(f'Test Precision: {test_precision:}')\n",
    "    print(f'Test Recall: {test_recall:}')\n",
    "    print(f'Test F1 Score: {test_f1:}')"
   ],
   "id": "b9c57aaf07b96d6f",
   "outputs": [],
   "execution_count": 111
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T13:05:32.411392Z",
     "start_time": "2025-01-06T13:05:31.497087Z"
    }
   },
   "cell_type": "code",
   "source": "test(model=model_gcn, dataset=data)",
   "id": "c4daa1a2101860b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7614457831325301\n",
      "Test Precision: 0.6880614314691393\n",
      "Test Recall: 0.6167476164777838\n",
      "Test F1 Score: 0.6289321808870946\n"
     ]
    }
   ],
   "execution_count": 112
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:48:53.023997400Z",
     "start_time": "2024-11-08T12:21:30.810857Z"
    }
   },
   "cell_type": "code",
   "source": "from sklearn.cluster import KMeans",
   "id": "3b0ea2cc472ef3b0",
   "outputs": [],
   "execution_count": 178
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:48:53.023997400Z",
     "start_time": "2024-12-04T21:53:51.927694Z"
    }
   },
   "cell_type": "code",
   "source": "from sklearn.cluster import AgglomerativeClustering",
   "id": "11330619588a0aa9",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:48:53.023997400Z",
     "start_time": "2024-12-04T21:55:33.690183Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "c5be10528a98e229",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# USING Class Weighting",
   "id": "f8d5a184d4485b04"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:51:29.543505Z",
     "start_time": "2025-01-06T12:51:29.538492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np"
   ],
   "id": "e28187f970e010d1",
   "outputs": [],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T13:05:42.436017Z",
     "start_time": "2025-01-06T13:05:42.425018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "labels = data.y.cpu().numpy() \n",
    "classes = np.unique(labels)"
   ],
   "id": "70bcd0e82c741fb1",
   "outputs": [],
   "execution_count": 113
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T13:05:43.131868Z",
     "start_time": "2025-01-06T13:05:43.116196Z"
    }
   },
   "cell_type": "code",
   "source": "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=labels)",
   "id": "f59561820c8fc1bc",
   "outputs": [],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T13:05:43.613298Z",
     "start_time": "2025-01-06T13:05:43.594117Z"
    }
   },
   "cell_type": "code",
   "source": "weights = torch.tensor(class_weights, dtype=torch.float) ",
   "id": "e48b034ab7260a29",
   "outputs": [],
   "execution_count": 115
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T13:05:44.023440Z",
     "start_time": "2025-01-06T13:05:44.013210Z"
    }
   },
   "cell_type": "code",
   "source": "criterion2 = torch.nn.BCEWithLogitsLoss(pos_weight=weights[1])\n",
   "id": "65c3e7ac91e2523a",
   "outputs": [],
   "execution_count": 116
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T13:05:45.087683Z",
     "start_time": "2025-01-06T13:05:45.071685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_gcn2 = GCN()\n",
    "optimizer = Adam(model_gcn.parameters(), lr=0.001)"
   ],
   "id": "97e46d5bab8b29ab",
   "outputs": [],
   "execution_count": 117
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T13:07:05.813574Z",
     "start_time": "2025-01-06T13:05:48.699822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train(model=model_gcn2, dataset=data,\n",
    "      criterion=criterion2, optimizer=optimizer,\n",
    "      epochs=50)"
   ],
   "id": "14a7fcfecb1ffe4c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Train Loss: 0.8515, Val Loss: 0.8629\n",
      "Epoch: 001, Train Loss: 0.8511, Val Loss: 0.8630\n",
      "Epoch: 002, Train Loss: 0.8517, Val Loss: 0.8622\n",
      "Epoch: 003, Train Loss: 0.8504, Val Loss: 0.8625\n",
      "Epoch: 004, Train Loss: 0.8516, Val Loss: 0.8630\n",
      "Epoch: 005, Train Loss: 0.8518, Val Loss: 0.8619\n",
      "Epoch: 006, Train Loss: 0.8501, Val Loss: 0.8619\n",
      "Epoch: 007, Train Loss: 0.8506, Val Loss: 0.8613\n",
      "Epoch: 008, Train Loss: 0.8516, Val Loss: 0.8628\n",
      "Epoch: 009, Train Loss: 0.8509, Val Loss: 0.8631\n",
      "Epoch: 010, Train Loss: 0.8519, Val Loss: 0.8628\n",
      "Epoch: 011, Train Loss: 0.8507, Val Loss: 0.8616\n",
      "Epoch: 012, Train Loss: 0.8507, Val Loss: 0.8614\n",
      "Epoch: 013, Train Loss: 0.8510, Val Loss: 0.8619\n",
      "Epoch: 014, Train Loss: 0.8516, Val Loss: 0.8627\n",
      "Epoch: 015, Train Loss: 0.8511, Val Loss: 0.8620\n",
      "Epoch: 016, Train Loss: 0.8508, Val Loss: 0.8630\n",
      "Epoch: 017, Train Loss: 0.8518, Val Loss: 0.8625\n",
      "Epoch: 018, Train Loss: 0.8508, Val Loss: 0.8624\n",
      "Epoch: 019, Train Loss: 0.8502, Val Loss: 0.8616\n",
      "Epoch: 020, Train Loss: 0.8520, Val Loss: 0.8628\n",
      "Epoch: 021, Train Loss: 0.8517, Val Loss: 0.8632\n",
      "Epoch: 022, Train Loss: 0.8522, Val Loss: 0.8625\n",
      "Epoch: 023, Train Loss: 0.8516, Val Loss: 0.8626\n",
      "Epoch: 024, Train Loss: 0.8506, Val Loss: 0.8612\n",
      "Epoch: 025, Train Loss: 0.8518, Val Loss: 0.8622\n",
      "Epoch: 026, Train Loss: 0.8504, Val Loss: 0.8621\n",
      "Epoch: 027, Train Loss: 0.8521, Val Loss: 0.8634\n",
      "Epoch: 028, Train Loss: 0.8522, Val Loss: 0.8637\n",
      "Epoch: 029, Train Loss: 0.8512, Val Loss: 0.8620\n",
      "Epoch: 030, Train Loss: 0.8513, Val Loss: 0.8622\n",
      "Epoch: 031, Train Loss: 0.8519, Val Loss: 0.8637\n",
      "Epoch: 032, Train Loss: 0.8516, Val Loss: 0.8632\n",
      "Epoch: 033, Train Loss: 0.8505, Val Loss: 0.8621\n",
      "Epoch: 034, Train Loss: 0.8508, Val Loss: 0.8622\n",
      "Epoch: 035, Train Loss: 0.8517, Val Loss: 0.8627\n",
      "Epoch: 036, Train Loss: 0.8510, Val Loss: 0.8614\n",
      "Epoch: 037, Train Loss: 0.8512, Val Loss: 0.8614\n",
      "Epoch: 038, Train Loss: 0.8522, Val Loss: 0.8631\n",
      "Epoch: 039, Train Loss: 0.8516, Val Loss: 0.8626\n",
      "Epoch: 040, Train Loss: 0.8506, Val Loss: 0.8628\n",
      "Epoch: 041, Train Loss: 0.8506, Val Loss: 0.8621\n",
      "Epoch: 042, Train Loss: 0.8514, Val Loss: 0.8624\n",
      "Epoch: 043, Train Loss: 0.8507, Val Loss: 0.8622\n",
      "Epoch: 044, Train Loss: 0.8506, Val Loss: 0.8621\n",
      "Epoch: 045, Train Loss: 0.8511, Val Loss: 0.8625\n",
      "Epoch: 046, Train Loss: 0.8506, Val Loss: 0.8615\n",
      "Epoch: 047, Train Loss: 0.8508, Val Loss: 0.8621\n",
      "Epoch: 048, Train Loss: 0.8505, Val Loss: 0.8621\n",
      "Epoch: 049, Train Loss: 0.8509, Val Loss: 0.8613\n"
     ]
    }
   ],
   "execution_count": 118
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T13:08:04.715493Z",
     "start_time": "2025-01-06T13:08:03.863129Z"
    }
   },
   "cell_type": "code",
   "source": "test(model=model_gcn2, dataset=data)",
   "id": "925cff18627ba1b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7373493975903614\n",
      "Test Precision: 0.3686746987951807\n",
      "Test Recall: 0.5\n",
      "Test F1 Score: 0.42441054091539526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\PycharmProjects\\Manu_factoid_GCN\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "execution_count": 120
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## FAKE WEIGHTS",
   "id": "3a4b69a7b1c6c964"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:48:53.025875600Z",
     "start_time": "2024-12-05T14:01:59.813664Z"
    }
   },
   "cell_type": "code",
   "source": "weights[1]",
   "id": "e129eb1edbfb3e89",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9107)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:48:53.025875600Z",
     "start_time": "2024-12-05T14:02:00.415307Z"
    }
   },
   "cell_type": "code",
   "source": "fake_weight=torch.tensor(2.5)",
   "id": "181e99cdf1994ef6",
   "outputs": [],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:48:53.025875600Z",
     "start_time": "2024-12-05T14:02:00.925993Z"
    }
   },
   "cell_type": "code",
   "source": "criterion3 = torch.nn.BCEWithLogitsLoss(pos_weight=fake_weight)\n",
   "id": "d291c546508c3933",
   "outputs": [],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:48:53.025875600Z",
     "start_time": "2024-12-05T14:02:01.333325Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train(model=model_gcn, dataset=data,\n",
    "      criterion=criterion3, optimizer=optimizer,\n",
    "      epochs=50)"
   ],
   "id": "2c2ea8cea4fc9db9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.8760\n",
      "Epoch: 001, Loss: 0.8475\n",
      "Epoch: 002, Loss: 0.8552\n",
      "Epoch: 003, Loss: 0.8509\n",
      "Epoch: 004, Loss: 0.8515\n",
      "Epoch: 005, Loss: 0.8597\n",
      "Epoch: 006, Loss: 0.8483\n",
      "Epoch: 007, Loss: 0.8585\n",
      "Epoch: 008, Loss: 0.8648\n",
      "Epoch: 009, Loss: 0.8415\n",
      "Epoch: 010, Loss: 0.8422\n",
      "Epoch: 011, Loss: 0.8548\n",
      "Epoch: 012, Loss: 0.8448\n",
      "Epoch: 013, Loss: 0.8604\n",
      "Epoch: 014, Loss: 0.8491\n",
      "Epoch: 015, Loss: 0.8452\n",
      "Epoch: 016, Loss: 0.8487\n",
      "Epoch: 017, Loss: 0.8586\n",
      "Epoch: 018, Loss: 0.8624\n",
      "Epoch: 019, Loss: 0.8445\n",
      "Epoch: 020, Loss: 0.8388\n",
      "Epoch: 021, Loss: 0.8555\n",
      "Epoch: 022, Loss: 0.8540\n",
      "Epoch: 023, Loss: 0.8532\n",
      "Epoch: 024, Loss: 0.8429\n",
      "Epoch: 025, Loss: 0.8584\n",
      "Epoch: 026, Loss: 0.8514\n",
      "Epoch: 027, Loss: 0.8592\n",
      "Epoch: 028, Loss: 0.8484\n",
      "Epoch: 029, Loss: 0.8436\n",
      "Epoch: 030, Loss: 0.8495\n",
      "Epoch: 031, Loss: 0.8462\n",
      "Epoch: 032, Loss: 0.8428\n",
      "Epoch: 033, Loss: 0.8470\n",
      "Epoch: 034, Loss: 0.8442\n",
      "Epoch: 035, Loss: 0.8506\n",
      "Epoch: 036, Loss: 0.8413\n",
      "Epoch: 037, Loss: 0.8414\n",
      "Epoch: 038, Loss: 0.8412\n",
      "Epoch: 039, Loss: 0.8415\n",
      "Epoch: 040, Loss: 0.8433\n",
      "Epoch: 041, Loss: 0.8462\n",
      "Epoch: 042, Loss: 0.8382\n",
      "Epoch: 043, Loss: 0.8317\n",
      "Epoch: 044, Loss: 0.8356\n",
      "Epoch: 045, Loss: 0.8350\n",
      "Epoch: 046, Loss: 0.8508\n",
      "Epoch: 047, Loss: 0.8447\n",
      "Epoch: 048, Loss: 0.8398\n",
      "Epoch: 049, Loss: 0.8355\n"
     ]
    }
   ],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:48:53.034012700Z",
     "start_time": "2024-12-04T22:13:26.424126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_geometric.utils import to_networkx\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx"
   ],
   "id": "1206f4be90a5dd3f",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:48:53.034012700Z",
     "start_time": "2024-12-04T22:36:21.899938Z"
    }
   },
   "cell_type": "code",
   "source": "G = to_networkx(data, to_undirected=True)\n",
   "id": "bca6d060fff523f1",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:48:53.034012700Z",
     "start_time": "2024-12-04T22:36:27.200763Z"
    }
   },
   "cell_type": "code",
   "source": "nx.write_gexf(G,\"graph_data_with.gexf\")",
   "id": "ee03d03bf4464901",
   "outputs": [],
   "execution_count": 54
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "manu_factoid",
   "language": "python",
   "name": "manu_factoid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
